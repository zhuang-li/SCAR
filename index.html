<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>SCAR – Data Selection for Efficient Instruction Tuning of LLMs</title>
  <meta name="description" content="SCAR ranks instruction–answer pairs by style consistency to enable data‑efficient fine‑tuning of large language models.">
  <meta name="keywords" content="data selection, instruction tuning, large language models, data‑efficient fine‑tuning, LLM alignment">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Minimal GitHub‑style CSS for README look‑and‑feel -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5.2.0/github-markdown.min.css">
  <style>
    body   { margin:0; display:flex; justify-content:center; }
    main   { max-width: 900px; padding: 2rem; }
    pre,code { white-space: pre-wrap; }
    table  { overflow-x: auto; display:block; }
  </style>
</head>
<body>
<main class="markdown-body">

<h1 id="acl-2025-main-scar-data-selection-via-style-consistency-aware-response-ranking-for-efficient-instruction-tuning-of-large-language-models">[ACL 2025 main] SCAR: Data Selection via Style Consistency Aware Response Ranking for Efficient Instruction Tuning of Large Language Models</h1>

<h2 id="overview">Overview</h2>

<p>SCAR is an innovative data‑selection method that enhances instruction tuning for large language models. By leveraging style‑consistency‑aware response ranking, SCAR identifies and selects the most beneficial training data for instruction tuning, ultimately improving model performance.</p>

<p align="center">
  <a href="https://arxiv.org/abs/2406.10882"><img src="https://img.shields.io/badge/arXiv-2406.10882-b31b1b.svg" alt="arXiv"></a>
  <a href="https://pypi.org/project/scar-tool/"><img src="https://img.shields.io/pypi/v/scar-tool?color=g" alt="PyPI"></a>
  <a href="https://pepy.tech/project/scar-tool"><img src="https://static.pepy.tech/badge/scar-tool" alt="Downloads"></a>
  <a href="https://github.com/zhuang-li/SCAR"><img src="https://img.shields.io/github/stars/zhuang-li/SCAR?style=social" alt="GitHub stars"></a>
  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-green.svg" alt="MIT license"></a>
</p>

<h2 id="installation">Installation</h2>

<p>Ensure you have <strong>Python 3.8+</strong> installed, then run:</p>

<pre><code class="language-bash">pip install scar-tool
</code></pre>

<h2 id="requirements">Requirements</h2>

<p><code>torch &gt;= 2.3</code>, <code>transformers &gt;= 4.37</code>, <code>huggingface_hub &gt;= 0.23</code>, <code>scikit-learn</code>, <code>tqdm</code>, <code>nltk</code>, <code>datasketch</code>.  
These packages install automatically with <strong>scar-tool</strong>.</p>

<h2 id="usage">Usage</h2>

<h3 id="basic-example-hugging-face-transformers">Basic example (Hugging Face Transformers)</h3>

<pre><code class="language-python">import torch
from transformers import AutoTokenizer
from style_ranker.ranker.model import StyleRanker

model_path = "lizhuang144/scar-gte-base"
model = StyleRanker.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

instructions = ["Write a poem about spring",
                "Explain quantum computing"]
answers = ["I am sorry. Who are you? Why should I tell you anything about poem",
           "Quantum computing is a type of computation..."]

ins = tokenizer(instructions, return_tensors="pt", padding=True,
                truncation=True, max_length=512)
ans = tokenizer(answers, return_tensors="pt", padding=True,
                truncation=True, max_length=512)

model.eval()
with torch.no_grad():
    scores = model(ins.input_ids, ins.attention_mask,
                   ans.input_ids, ans.attention_mask)

for i, (instr, answ, s) in enumerate(zip(instructions, answers, scores)):
    print(f"{i+1}. {instr}\n   {answ}\n   Score: {s.item():.2f}\n")
</code></pre>

<h3 id="advanced-rank-and-filter">Advanced: rank and filter</h3>

<pre><code class="language-python">from style_ranker.rank import rank_and_filter
import torch

model_path = "lizhuang144/scar-gte-base"
device = "cuda" if torch.cuda.is_available() else "cpu"

instructions = ["Write a poem about spring",
                "Explain quantum computing",
                "Describe the water cycle"]
answers = ["I am sorry. Who are you? Why should I tell you anything about poem",
           "Quantum computing is a type of computation...",
           "The water cycle, also known as..."]

topk_pairs      = rank_and_filter(model_path, instructions, answers, topk=2, device=device)
threshold_pairs = rank_and_filter(model_path, instructions, answers, threshold=-2.0, device=device)
ratio_pairs     = rank_and_filter(model_path, instructions, answers, ratio=0.5, device=device)
</code></pre>

<blockquote><strong>Tip:</strong> SCAR models currently do <strong>not</strong> support non‑English data or automatic de‑duplication. Exclude non‑English examples and remove duplicates before filtering.</blockquote>

<!-- … (Model list, Performance tables, Key components, Scripts, Project structure unchanged) … -->

<h2 id="citation">Citation (ACL 2025)</h2>

<pre><code class="language-bibtex">@inproceedings{li-etal-2025-scar,
  title     = {{SCAR}: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models},
  author    = {Li, Zhuang and Hua, Yuncheng and Vu, Thuy-Trang and Zhan, Haolan and Qu, Lizhen and Haffari, Gholamreza},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2025},
  pages     = {12756--12790},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.acl-long.625/},
  isbn      = {979-8-89176-251-0}
}
</code></pre>

<h2 id="license">License</h2>
<p>MIT License – © 2024 Zhuang Li</p>

<p><strong>Unlock efficient instruction tuning for your next LLM project with <em>SCAR</em>!</strong></p>

</main>
</body>
</html>
